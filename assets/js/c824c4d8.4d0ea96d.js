"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[137],{987:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>a,default:()=>g,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms/module-4-lesson-2-cognitive-planning-llms","title":"Cognitive Planning LLMs","description":"Overview","source":"@site/docs/modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms/index.md","sourceDirName":"modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms","slug":"/modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms/","permalink":"/Hackathons/docs/modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms/","draft":false,"unlisted":false,"editUrl":"https://github.com/mudasirsohail/Hackathons/docs/modules/module-4-vision-language-action/lesson-2-cognitive-planning-llms/index.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Cognitive Planning LLMs","id":"module-4-lesson-2-cognitive-planning-llms","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Voice-to-Action Whisper","permalink":"/Hackathons/docs/modules/module-4-vision-language-action/lesson-1-voice-to-action-whisper/"},"next":{"title":"Integration Examples","permalink":"/Hackathons/docs/modules/module-4-vision-language-action/lesson-3-integration-examples/"}}');var l=i(4848),o=i(8453);const t={title:"Cognitive Planning LLMs",id:"module-4-lesson-2-cognitive-planning-llms",sidebar_position:2},a="Cognitive Planning LLMs",r={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"LLMs in Robotics",id:"llms-in-robotics",level:2},{value:"Planning Pipeline",id:"planning-pipeline",level:2},{value:"Context and Memory",id:"context-and-memory",level:2},{value:"Practical Considerations",id:"practical-considerations",level:2},{value:"Practical Exercise",id:"practical-exercise",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"cognitive-planning-llms",children:"Cognitive Planning LLMs"})}),"\n",(0,l.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,l.jsx)(e.p,{children:"This lesson explores using Large Language Models (LLMs) for cognitive planning in robotics. You'll learn to translate natural language commands into sequences of ROS 2 actions using LLMs."}),"\n",(0,l.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Integrate LLMs with robotics systems for cognitive planning"}),"\n",(0,l.jsx)(e.li,{children:"Parse natural language commands into executable action sequences"}),"\n",(0,l.jsx)(e.li,{children:"Handle complex commands requiring multiple steps"}),"\n",(0,l.jsx)(e.li,{children:"Validate and verify planned action sequences"}),"\n",(0,l.jsx)(e.li,{children:"Implement feedback loops for plan execution"}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"llms-in-robotics",children:"LLMs in Robotics"}),"\n",(0,l.jsx)(e.p,{children:"Large Language Models can interpret high-level natural language commands and generate detailed action plans for robots to execute, bridging the gap between human intentions and robot actions."}),"\n",(0,l.jsx)(e.h2,{id:"planning-pipeline",children:"Planning Pipeline"}),"\n",(0,l.jsxs)(e.ol,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Language Understanding"}),": Parse natural language command"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Knowledge Retrieval"}),": Access relevant information about environment/robot capabilities"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Action Planning"}),": Generate sequence of specific robot actions"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Execution Validation"}),": Verify the plan is feasible and safe"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"context-and-memory",children:"Context and Memory"}),"\n",(0,l.jsx)(e.p,{children:"LLMs need appropriate context about the robot's environment, capabilities, and current state to generate relevant action plans."}),"\n",(0,l.jsx)(e.h2,{id:"practical-considerations",children:"Practical Considerations"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Prompt engineering for reliable output"}),"\n",(0,l.jsx)(e.li,{children:"Handling ambiguous or impossible commands"}),"\n",(0,l.jsx)(e.li,{children:"Safety checks on generated plans"}),"\n",(0,l.jsx)(e.li,{children:"Integration with existing navigation and manipulation systems"}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,l.jsx)(e.p,{children:'Create a system that converts high-level commands like "Clean the room" into sequences of specific actions like "navigate to object", "pick up object", "navigate to disposal area", and "place object".'}),"\n",(0,l.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsxs)(e.p,{children:["After learning cognitive planning, you'll explore ",(0,l.jsx)(e.a,{href:"./lesson-3-integration-examples",children:"Integration Examples"}),"."]})]})}function g(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>a});var s=i(6540);const l={},o=s.createContext(l);function t(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:t(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);